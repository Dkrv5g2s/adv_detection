{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-30T18:58:21.319237Z",
     "start_time": "2025-07-30T18:58:08.165528Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "import shap\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用裝置: {device}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用裝置: cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T18:58:21.540133Z",
     "start_time": "2025-07-30T18:58:21.480050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=False)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "train_loader, test_loader = load_data()\n"
   ],
   "id": "e12826f3976d8c84",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T18:58:21.707730Z",
     "start_time": "2025-07-30T18:58:21.550704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return x  # last hidden layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ],
   "id": "483ba9ad16c19cec",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T19:00:03.406100Z",
     "start_time": "2025-07-30T18:58:21.723350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_classifier(model, train_loader, criterion, optimizer, device, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "train_classifier(model, train_loader, criterion, optimizer, device)\n"
   ],
   "id": "21454fb938a5e700",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 106.3924\n",
      "Epoch 2/10, Loss: 25.7188\n",
      "Epoch 3/10, Loss: 17.9877\n",
      "Epoch 4/10, Loss: 13.7938\n",
      "Epoch 5/10, Loss: 10.7899\n",
      "Epoch 6/10, Loss: 8.7712\n",
      "Epoch 7/10, Loss: 6.6144\n",
      "Epoch 8/10, Loss: 5.5020\n",
      "Epoch 9/10, Loss: 5.0525\n",
      "Epoch 10/10, Loss: 3.4527\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T19:00:07.042260Z",
     "start_time": "2025-07-30T19:00:03.484549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    clip_values=(0, 1),\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=(1, 28, 28),\n",
    "    nb_classes=10,\n",
    ")\n",
    "\n",
    "def generate_adversarial_samples(classifier, test_loader):\n",
    "    attack = FastGradientMethod(estimator=classifier, eps=0.1)\n",
    "    adversarial_samples = []\n",
    "    normal_samples = []\n",
    "    for images, labels in test_loader:\n",
    "        adversarial_images = attack.generate(x=images.cpu().numpy())\n",
    "        adversarial_samples.append((adversarial_images, labels.numpy()))\n",
    "        normal_samples.append((images.numpy(), labels.numpy()))\n",
    "    return normal_samples, adversarial_samples\n",
    "\n",
    "normal_samples, adversarial_samples = generate_adversarial_samples(classifier, test_loader)\n"
   ],
   "id": "59f28ac8753bb6e4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T01:44:22.112454Z",
     "start_time": "2025-07-30T19:00:07.051823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FeatureModel(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(FeatureModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model.forward_features(x)\n",
    "\n",
    "feature_model = FeatureModel(model).to(device)\n",
    "feature_model.eval()\n",
    "\n",
    "def generate_shap_signatures(feature_model, samples, num_classes=10):\n",
    "    feature_model.eval()\n",
    "    background = torch.tensor(samples[0][0][:50], dtype=torch.float32).to(device)\n",
    "    explainer = shap.DeepExplainer(feature_model, background)\n",
    "\n",
    "    shap_signatures = []\n",
    "\n",
    "    for images, labels in samples:\n",
    "        images_tensor = torch.tensor(images, dtype=torch.float32).to(device)\n",
    "        shap_list = explainer.shap_values(images_tensor, check_additivity=False)\n",
    "        concatenated = np.concatenate(shap_list, axis=1)  # shape: (batch, num_classes * feature_size)\n",
    "        shap_signatures.append((concatenated, labels))\n",
    "    return shap_signatures\n",
    "\n",
    "normal_shap_signatures = generate_shap_signatures(feature_model, normal_samples)\n",
    "adversarial_shap_signatures = generate_shap_signatures(feature_model, adversarial_samples)\n"
   ],
   "id": "a2830424a02e5b4e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T01:44:26.796484Z",
     "start_time": "2025-07-31T01:44:22.280857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DetectorModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DetectorModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(1280, 256)  # 10 * 128\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 16)\n",
    "        self.fc4 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "detector = DetectorModel().to(device)\n",
    "detector_criterion = nn.BCELoss()\n",
    "detector_optimizer = optim.Adam(detector.parameters(), lr=0.001)\n",
    "\n",
    "def train_detector(detector, normal_signatures, adversarial_signatures, epochs=10):\n",
    "    detector.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for normal, adversarial in zip(normal_signatures, adversarial_signatures):\n",
    "            normal_features, normal_labels = normal\n",
    "            adversarial_features, adversarial_labels = adversarial\n",
    "\n",
    "            features = torch.tensor(\n",
    "                np.concatenate([normal_features, adversarial_features], axis=0),\n",
    "                dtype=torch.float32\n",
    "            ).to(device)\n",
    "            labels = torch.cat([\n",
    "                torch.zeros(len(normal_labels)),\n",
    "                torch.ones(len(adversarial_labels))\n",
    "            ], dim=0).to(device)\n",
    "\n",
    "            detector_optimizer.zero_grad()\n",
    "            outputs = detector(features).squeeze()\n",
    "            loss = detector_criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            detector_optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Detector Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "train_detector(detector, normal_shap_signatures, adversarial_shap_signatures)\n"
   ],
   "id": "d7aa3e801bd58aba",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (200704x128 and 1280x256)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 45\u001B[39m\n\u001B[32m     42\u001B[39m             total_loss += loss.item()\n\u001B[32m     43\u001B[39m         \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mDetector Epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch+\u001B[32m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtotal_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m45\u001B[39m \u001B[43mtrain_detector\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdetector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormal_shap_signatures\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madversarial_shap_signatures\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 38\u001B[39m, in \u001B[36mtrain_detector\u001B[39m\u001B[34m(detector, normal_signatures, adversarial_signatures, epochs)\u001B[39m\n\u001B[32m     32\u001B[39m labels = torch.cat([\n\u001B[32m     33\u001B[39m     torch.zeros(\u001B[38;5;28mlen\u001B[39m(normal_labels)),\n\u001B[32m     34\u001B[39m     torch.ones(\u001B[38;5;28mlen\u001B[39m(adversarial_labels))\n\u001B[32m     35\u001B[39m ], dim=\u001B[32m0\u001B[39m).to(device)\n\u001B[32m     37\u001B[39m detector_optimizer.zero_grad()\n\u001B[32m---> \u001B[39m\u001B[32m38\u001B[39m outputs = \u001B[43mdetector\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m.squeeze()\n\u001B[32m     39\u001B[39m loss = detector_criterion(outputs, labels)\n\u001B[32m     40\u001B[39m loss.backward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mc:\\Users\\Ted\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1734\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1735\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1736\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mc:\\Users\\Ted\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1742\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1743\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1745\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1746\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1747\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1749\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1750\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 10\u001B[39m, in \u001B[36mDetectorModel.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m     x = torch.relu(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfc1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m     11\u001B[39m     x = torch.relu(\u001B[38;5;28mself\u001B[39m.fc2(x))\n\u001B[32m     12\u001B[39m     x = torch.relu(\u001B[38;5;28mself\u001B[39m.fc3(x))\n",
      "\u001B[36mFile \u001B[39m\u001B[32mc:\\Users\\Ted\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1734\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1735\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1736\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mc:\\Users\\Ted\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1742\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1743\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1745\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1746\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1747\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1749\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1750\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mc:\\Users\\Ted\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mRuntimeError\u001B[39m: mat1 and mat2 shapes cannot be multiplied (200704x128 and 1280x256)"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
