{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-31T07:07:39.512115Z",
     "start_time": "2025-07-31T07:07:25.544561Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "import shap\n",
    "\n",
    "# 使用裝置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用裝置: {device}\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用裝置: cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T07:07:39.592630Z",
     "start_time": "2025-07-31T07:07:39.522818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 資料加載\n",
    "def load_data():\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=False)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = load_data()\n",
    "\n"
   ],
   "id": "d1a5198246081458",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T07:07:39.916454Z",
     "start_time": "2025-07-31T07:07:39.778429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# PyTorch 模型\n",
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # 計算卷積層輸出大小，假設輸入大小為 (1, 28, 28)\n",
    "        self.fc = nn.Linear(64 * 5 * 5, 10)  # 修改輸入大小\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MNISTModel().to(device)\n"
   ],
   "id": "f690a9fac8ef6f0c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T07:10:25.067059Z",
     "start_time": "2025-07-31T07:09:10.391839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 訓練目標模型\n",
    "def train_classifier(model, train_loader, epochs=10):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss:.4f}\")\n",
    "\n",
    "\n",
    "train_classifier(model, train_loader)\n"
   ],
   "id": "e7e7bbb7ecafeff1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 11.3758\n",
      "Epoch [2/10], Loss: 9.5694\n",
      "Epoch [3/10], Loss: 7.9750\n",
      "Epoch [4/10], Loss: 7.0070\n",
      "Epoch [5/10], Loss: 6.0901\n",
      "Epoch [6/10], Loss: 5.0333\n",
      "Epoch [7/10], Loss: 4.5339\n",
      "Epoch [8/10], Loss: 4.0691\n",
      "Epoch [9/10], Loss: 3.2847\n",
      "Epoch [10/10], Loss: 3.3009\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T07:15:53.518638Z",
     "start_time": "2025-07-31T07:15:53.511223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ART PyTorchClassifier\n",
    "classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    loss=nn.CrossEntropyLoss(),\n",
    "    optimizer=optim.Adam(model.parameters(), lr=0.001),\n",
    "    input_shape=(1, 28, 28),\n",
    "    nb_classes=10,\n",
    ")\n",
    "\n"
   ],
   "id": "f7ac086efd5e6b1f",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T07:15:58.435270Z",
     "start_time": "2025-07-31T07:15:55.213985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 生成對抗樣本\n",
    "def generate_adversarial_samples(classifier, test_loader):\n",
    "    attack = FastGradientMethod(estimator=classifier, eps=0.1)\n",
    "    adversarial_samples = []\n",
    "    normal_samples = []\n",
    "    for images, labels in test_loader:\n",
    "        images = images.numpy().reshape(-1, 1, 28, 28)  # 確保形狀正確\n",
    "        adversarial_images = attack.generate(x=images)\n",
    "        adversarial_samples.append((adversarial_images, labels.numpy()))\n",
    "        normal_samples.append((images, labels.numpy()))\n",
    "    return normal_samples, adversarial_samples\n",
    "\n",
    "normal_samples, adversarial_samples = generate_adversarial_samples(classifier, test_loader)\n",
    "\n",
    "\n"
   ],
   "id": "288675fef09d72ef",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T07:16:13.025039Z",
     "start_time": "2025-07-31T07:15:58.454488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SHAP 簽名生成\n",
    "def generate_shap_signatures(model, samples, num_classes=10):\n",
    "    # 使用樣本中的前 50 個作為背景資料\n",
    "    background = torch.tensor(samples[0][0][:50]).to(device)\n",
    "    background = background.reshape(-1, 1, 28, 28)  # MNIST 的輸入形狀\n",
    "    explainer = shap.DeepExplainer(model, background)\n",
    "    shap_signatures = []\n",
    "\n",
    "    for images, labels in samples:\n",
    "        images = torch.tensor(images).to(device)\n",
    "        images = images.reshape(-1, 1, 28, 28)  # 確保輸入形狀正確\n",
    "        shap_values = explainer.shap_values(images)\n",
    "\n",
    "        # 確保簽名大小正確\n",
    "        flattened = np.concatenate([shap_values[i].flatten() for i in range(num_classes)], axis=0)\n",
    "        print(\"SHAP 簽名大小:\", flattened.shape)  # 打印形狀檢查\n",
    "        shap_signatures.append((flattened, labels))\n",
    "    return shap_signatures\n",
    "\n",
    "\n",
    "\n",
    "normal_shap_signatures = generate_shap_signatures(model, normal_samples)\n",
    "adversarial_shap_signatures = generate_shap_signatures(model, adversarial_samples)\n",
    "\n"
   ],
   "id": "87e2e04dbb92c575",
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The SHAP explanations do not sum up to the model's output! This is either because of a rounding error or because an operator in your computation graph was not fully supported. If the sum difference of %f is significant compared to the scale of your model outputs, please post as a github issue, with a reproducible example so we can debug it. Used framework: pytorch - Max. diff: 18.664880711976622 - Tolerance: 0.01",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAssertionError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 22\u001B[39m\n\u001B[32m     17\u001B[39m         shap_signatures.append((flattened, labels))\n\u001B[32m     18\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m shap_signatures\n\u001B[32m---> \u001B[39m\u001B[32m22\u001B[39m normal_shap_signatures = \u001B[43mgenerate_shap_signatures\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormal_samples\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     23\u001B[39m adversarial_shap_signatures = generate_shap_signatures(model, adversarial_samples)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 12\u001B[39m, in \u001B[36mgenerate_shap_signatures\u001B[39m\u001B[34m(model, samples, num_classes)\u001B[39m\n\u001B[32m     10\u001B[39m images = torch.tensor(images).to(device)\n\u001B[32m     11\u001B[39m images = images.reshape(-\u001B[32m1\u001B[39m, \u001B[32m1\u001B[39m, \u001B[32m28\u001B[39m, \u001B[32m28\u001B[39m)  \u001B[38;5;66;03m# 確保輸入形狀正確\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m12\u001B[39m shap_values = \u001B[43mexplainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mshap_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[38;5;66;03m# 確保簽名大小正確\u001B[39;00m\n\u001B[32m     15\u001B[39m flattened = np.concatenate([shap_values[i].flatten() \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_classes)], axis=\u001B[32m0\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mc:\\Users\\Ted\\anaconda3\\Lib\\site-packages\\shap\\explainers\\_deep\\__init__.py:164\u001B[39m, in \u001B[36mDeepExplainer.shap_values\u001B[39m\u001B[34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001B[39m\n\u001B[32m    120\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mshap_values\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, ranked_outputs=\u001B[38;5;28;01mNone\u001B[39;00m, output_rank_order=\u001B[33m\"\u001B[39m\u001B[33mmax\u001B[39m\u001B[33m\"\u001B[39m, check_additivity=\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[32m    121\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Return approximate SHAP values for the model applied to the data given by X.\u001B[39;00m\n\u001B[32m    122\u001B[39m \n\u001B[32m    123\u001B[39m \u001B[33;03m    Parameters\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    162\u001B[39m \n\u001B[32m    163\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m164\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mexplainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mshap_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mranked_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_rank_order\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_additivity\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcheck_additivity\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mc:\\Users\\Ted\\anaconda3\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_pytorch.py:226\u001B[39m, in \u001B[36mPyTorchDeep.shap_values\u001B[39m\u001B[34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001B[39m\n\u001B[32m    223\u001B[39m         \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m    224\u001B[39m             model_output_values = \u001B[38;5;28mself\u001B[39m.model(*X)\n\u001B[32m--> \u001B[39m\u001B[32m226\u001B[39m     \u001B[43m_check_additivity\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_output_values\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_phis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    228\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output_phis, \u001B[38;5;28mlist\u001B[39m):\n\u001B[32m    229\u001B[39m     \u001B[38;5;66;03m# in this case we have multiple inputs and potentially multiple outputs\u001B[39;00m\n\u001B[32m    230\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output_phis[\u001B[32m0\u001B[39m], \u001B[38;5;28mlist\u001B[39m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32mc:\\Users\\Ted\\anaconda3\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_utils.py:26\u001B[39m, in \u001B[36m_check_additivity\u001B[39m\u001B[34m(explainer, model_output_values, output_phis)\u001B[39m\n\u001B[32m     22\u001B[39m         diffs -= output_phis[t][i].sum(axis=\u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;28mrange\u001B[39m(\u001B[32m1\u001B[39m, output_phis[t][i].ndim)))\n\u001B[32m     24\u001B[39m maxdiff = np.abs(diffs).max()\n\u001B[32m---> \u001B[39m\u001B[32m26\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m maxdiff < TOLERANCE, (\n\u001B[32m     27\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mThe SHAP explanations do not sum up to the model\u001B[39m\u001B[33m'\u001B[39m\u001B[33ms output! This is either because of a \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     28\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mrounding error or because an operator in your computation graph was not fully supported. If \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     29\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mthe sum difference of \u001B[39m\u001B[38;5;132;01m%f\u001B[39;00m\u001B[33m is significant compared to the scale of your model outputs, please post \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     30\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mas a github issue, with a reproducible example so we can debug it. Used framework: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexplainer.framework\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m - Max. diff: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmaxdiff\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m - Tolerance: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mTOLERANCE\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m     31\u001B[39m )\n",
      "\u001B[31mAssertionError\u001B[39m: The SHAP explanations do not sum up to the model's output! This is either because of a rounding error or because an operator in your computation graph was not fully supported. If the sum difference of %f is significant compared to the scale of your model outputs, please post as a github issue, with a reproducible example so we can debug it. Used framework: pytorch - Max. diff: 18.664880711976622 - Tolerance: 0.01"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 偵測器模型\n",
    "class DetectorModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(DetectorModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)  # 修改輸入大小\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 16)\n",
    "        self.fc4 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # 確保展平輸入\n",
    "        print(\"Input shape:\", x.shape)  # 打印形狀\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "# 根據 SHAP簽名大小初始化偵測器模型\n",
    "input_size = normal_shap_signatures[0][0].shape[0]\n",
    "detector = DetectorModel(input_size).to(device)\n",
    "\n"
   ],
   "id": "1d1bca7e0c3d4cd3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 訓練偵測器模型\n",
    "def train_detector(detector, normal_signatures, adversarial_signatures, epochs=10):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(detector.parameters(), lr=0.001)\n",
    "\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for normal, adversarial in zip(normal_signatures, adversarial_signatures):\n",
    "        normal_features, normal_labels = normal\n",
    "        adversarial_features, adversarial_labels = adversarial\n",
    "\n",
    "        # 確保特徵和標籤形狀一致\n",
    "        features = np.concatenate([normal_features, adversarial_features], axis=0)\n",
    "        labels = np.concatenate([\n",
    "            np.zeros(len(normal_labels)),\n",
    "            np.ones(len(adversarial_labels))\n",
    "        ], axis=0)\n",
    "\n",
    "        x_train.append(features)\n",
    "        y_train.append(labels)\n",
    "\n",
    "    x_train = torch.tensor(np.concatenate(x_train, axis=0)).float().to(device)\n",
    "    y_train = torch.tensor(np.concatenate(y_train, axis=0)).float().to(device)\n",
    "\n",
    "    detector.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向傳播\n",
    "        outputs = detector(x_train)\n",
    "\n",
    "        # 計算損失\n",
    "        loss = criterion(outputs.squeeze(), y_train)\n",
    "\n",
    "        # 反向傳播\n",
    "        loss.backward()\n",
    "\n",
    "        # 更新參數\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "train_detector(detector, normal_shap_signatures, adversarial_shap_signatures)\n",
    "\n",
    "\n"
   ],
   "id": "c6670b88d8af1a77"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
